<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Kernels · GpABC</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://tanhevg.github.io/GpABC.jl/stable/ref-kernels/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">GpABC</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Package Overview</span><ul><li><a class="tocitem" href="../overview-abc/">ABC Parameter Inference</a></li><li><a class="tocitem" href="../overview-ms/">ABC Model Selection</a></li><li><a class="tocitem" href="../overview-lna/">LNA</a></li><li><a class="tocitem" href="../overview-gp/">Gaussian Process Regression</a></li><li><a class="tocitem" href="../summary_stats/">Summary Statistics</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../example-abc/">ABC Parameter Inference</a></li><li><a class="tocitem" href="../example-ms/">ABC Model Selection</a></li><li><a class="tocitem" href="../example-lna/">Stochastic inference (LNA)</a></li><li><a class="tocitem" href="../example-gp/">Gaussian Processes</a></li></ul></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../ref-abc/">ABC Basic</a></li><li><a class="tocitem" href="../ref-abc-advanced/">ABC Advanced</a></li><li><a class="tocitem" href="../ref-lna/">Stochastic inference (LNA)</a></li><li><a class="tocitem" href="../ref-ms/">Model Selection</a></li><li><a class="tocitem" href="../ref-gp/">Gaussian Processes</a></li><li class="is-active"><a class="tocitem" href>Kernels</a><ul class="internal"><li><a class="tocitem" href="#Index"><span>Index</span></a></li><li><a class="tocitem" href="#Types-and-Functions"><span>Types and Functions</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../faq/">FAQ</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Reference</a></li><li class="is-active"><a href>Kernels</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Kernels</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/tanhevg/GpABC.jl/blob/master/docs/src/ref-kernels.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Kernels-Reference"><a class="docs-heading-anchor" href="#Kernels-Reference">Kernels Reference</a><a id="Kernels-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Kernels-Reference" title="Permalink"></a></h1><p><code>GpABC</code> functions and types for working with kernels.</p><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#GpABC.AbstractGPKernel"><code>GpABC.AbstractGPKernel</code></a></li><li><a href="#GpABC.MaternArdKernel"><code>GpABC.MaternArdKernel</code></a></li><li><a href="#GpABC.MaternIsoKernel"><code>GpABC.MaternIsoKernel</code></a></li><li><a href="#GpABC.SquaredExponentialArdKernel"><code>GpABC.SquaredExponentialArdKernel</code></a></li><li><a href="#GpABC.SquaredExponentialIsoKernel"><code>GpABC.SquaredExponentialIsoKernel</code></a></li><li><a href="#GpABC.ExponentialArdKernel-Tuple{}"><code>GpABC.ExponentialArdKernel</code></a></li><li><a href="#GpABC.ExponentialIsoKernel-Tuple{}"><code>GpABC.ExponentialIsoKernel</code></a></li><li><a href="#GpABC.covariance-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>GpABC.covariance</code></a></li><li><a href="#GpABC.covariance_diagonal-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}}"><code>GpABC.covariance_diagonal</code></a></li><li><a href="#GpABC.covariance_grad-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>GpABC.covariance_grad</code></a></li><li><a href="#GpABC.covariance_training-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}}"><code>GpABC.covariance_training</code></a></li><li><a href="#GpABC.get_hyperparameters_size-Tuple{AbstractGPKernel, AbstractMatrix{Float64}}"><code>GpABC.get_hyperparameters_size</code></a></li><li><a href="#GpABC.scaled_squared_distance-Tuple{AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>GpABC.scaled_squared_distance</code></a></li><li><a href="#GpABC.scaled_squared_distance_grad-Tuple{AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>GpABC.scaled_squared_distance_grad</code></a></li></ul><h2 id="Types-and-Functions"><a class="docs-heading-anchor" href="#Types-and-Functions">Types and Functions</a><a id="Types-and-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Types-and-Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="GpABC.AbstractGPKernel" href="#GpABC.AbstractGPKernel"><code>GpABC.AbstractGPKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractGPKernel</code></pre><p>Abstract kernel type. User-defined kernels should derive from it.</p><p>Implementations have to provide methods for <a href="#GpABC.get_hyperparameters_size-Tuple{AbstractGPKernel, AbstractMatrix{Float64}}"><code>get_hyperparameters_size</code></a> and <a href="#GpABC.covariance-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>covariance</code></a>. Methods for <a href="#GpABC.covariance_training-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}}"><code>covariance_training</code></a>, <a href="#GpABC.covariance_diagonal-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}}"><code>covariance_diagonal</code></a> and <a href="#GpABC.covariance_grad-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>covariance_grad</code></a> are optional.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tanhevg/GpABC.jl/blob/1f65a998a3ca8c20b94e4ddce05578f2ea32a3d4/src/gp/kernels/abstract_kernel.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GpABC.covariance-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}" href="#GpABC.covariance-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>GpABC.covariance</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">covariance(ker::AbstractGPKernel, log_theta::AbstractArray{Float64, 1},
    x::AbstractArray{Float64, 2}, z::AbstractArray{Float64, 2})</code></pre><p>Return the covariance matrix. Should be overridden by kernel implementations.</p><p><strong>Arguments</strong></p><ul><li><code>ker</code>: The kernel object. Implementations must override with their own subtype.</li><li><code>log_theta</code>: natural logarithm of hyperparameters.</li><li><code>x, z</code>: Input data, reshaped into 2-d arrays. <code>x</code> must have dimensions <span>$n \times d$</span>; <code>z</code> must have dimensions <span>$m \times d$</span>.</li></ul><p><strong>Return</strong></p><p>The covariance matrix, of size <span>$n \times m$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tanhevg/GpABC.jl/blob/1f65a998a3ca8c20b94e4ddce05578f2ea32a3d4/src/gp/kernels/abstract_kernel.jl#L12-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GpABC.covariance_diagonal-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}}" href="#GpABC.covariance_diagonal-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}}"><code>GpABC.covariance_diagonal</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">covariance_diagonal(ker::AbstractGPKernel, log_theta::AbstractArray{Float64, 1},
    x::AbstractArray{Float64, 2})</code></pre><p>This is a speedup version of <a href="#GpABC.covariance-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>covariance</code></a>, which is invoked if the caller is not interested in the entire covariance matrix, but only needs the variance, i.e. the diagonal of the covariance matrix.</p><p>Default method just returns <code>diag(covariance(...))</code>, with <code>x === z</code>. Kernel implementations can optionally override it to achieve better performance, by not computing the non diagonal elements of covariance matrix.</p><p>See <a href="#GpABC.covariance-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>covariance</code></a> for description of arguments.</p><p><strong>Return</strong></p><p>The 1-d array of variances, of size <code>size(x, 1)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tanhevg/GpABC.jl/blob/1f65a998a3ca8c20b94e4ddce05578f2ea32a3d4/src/gp/kernels/abstract_kernel.jl#L49-L65">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GpABC.covariance_grad-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}" href="#GpABC.covariance_grad-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>GpABC.covariance_grad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">covariance_grad(ker::AbstractGPKernel, log_theta::AbstractArray{Float64, 1},
    x::AbstractArray{Float64, 2}, R::AbstractArray{Float64, 2})</code></pre><p>Return the gradient of the covariance function with respect to logarithms of hyperparameters, based on the provided direction matrix.</p><p>This function can be optionally overridden by kernel implementations. If the gradient function is not provided, <a href="../ref-gp/#GpABC.gp_train-Union{Tuple{GPModel}, Tuple{TOpt}} where TOpt&lt;:Optim.AbstractOptimizer"><code>gp_train</code></a> will fail back to <code>NelderMead</code> algorithm by default.</p><p><strong>Arguments</strong></p><ul><li><code>ker</code>: The kernel object. Implementations must override with their own subtype.</li><li><code>log_theta</code>:  natural logarithm of hyperparameters</li><li><code>x</code>: Training data, reshaped into a 2-d array. <code>x</code> must have dimensions <span>$n \times d$</span>.</li><li><code>R</code> the directional matrix, <span>$n \times n$</span></li></ul><p class="math-container">\[R = \frac{1}{\sigma_n^2}(\alpha * \alpha^T - K^{-1}); \alpha = K^{-1}y\]</p><p><strong>Return</strong></p><p>A vector of size <code>length(log_theta)</code>, whose <span>$j$</span>&#39;th element is equal to</p><p class="math-container">\[tr(R \frac{\partial K}{\partial \eta_j})\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tanhevg/GpABC.jl/blob/1f65a998a3ca8c20b94e4ddce05578f2ea32a3d4/src/gp/kernels/abstract_kernel.jl#L71-L97">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GpABC.covariance_training-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}}" href="#GpABC.covariance_training-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}}"><code>GpABC.covariance_training</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">covariance_training(ker::AbstractGPKernel, log_theta::AbstractArray{Float64, 1},
    training_x::AbstractArray{Float64, 2})</code></pre><p>This is a speedup version of <a href="#GpABC.covariance-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>covariance</code></a>, which is only called during training sequence. Intermediate matrices computed in this function for particular hyperparameters can be cached and reused subsequently, either in this function or in <a href="#GpABC.covariance_grad-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>covariance_grad</code></a></p><p>Default method just delegates to <a href="#GpABC.covariance-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>covariance</code></a> with <code>x === z</code>. Kernel implementations can optionally override it for better performance.</p><p>See <a href="#GpABC.covariance-Tuple{AbstractGPKernel, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>covariance</code></a> for description of arguments and return values.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tanhevg/GpABC.jl/blob/1f65a998a3ca8c20b94e4ddce05578f2ea32a3d4/src/gp/kernels/abstract_kernel.jl#L30-L43">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GpABC.get_hyperparameters_size-Tuple{AbstractGPKernel, AbstractMatrix{Float64}}" href="#GpABC.get_hyperparameters_size-Tuple{AbstractGPKernel, AbstractMatrix{Float64}}"><code>GpABC.get_hyperparameters_size</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_hyperparameters_size(kernel::AbstractGPKernel, training_data::AbstractArray{Float64, 2})</code></pre><p>Return the number of hyperparameters for used by this kernel on this training data set. Should be overridden by kernel implementations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tanhevg/GpABC.jl/blob/1f65a998a3ca8c20b94e4ddce05578f2ea32a3d4/src/gp/kernels/abstract_kernel.jl#L103-L108">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GpABC.MaternArdKernel" href="#GpABC.MaternArdKernel"><code>GpABC.MaternArdKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MaternArdKernel &lt;: AbstractGPKernel</code></pre><p>Matérn kernel with distinct length scale for each dimension, <span>$l_k$</span>. Parameter <span>$\nu$</span> (nu) is passed in constructor. Currently, only values of <span>$\nu=1$</span>, <span>$\nu=3$</span> and <span>$\nu=5$</span> are supported.</p><p class="math-container">\[\begin{aligned}
K_{\nu=1}(r) &amp;= \sigma_f^2e^{-\sqrt{r}}\\
K_{\nu=3}(r) &amp;= \sigma_f^2(1 + \sqrt{3r})e^{-\sqrt{3r}}\\
K_{\nu=5}(r) &amp;= \sigma_f^2(1 + \sqrt{3r} + \frac{5}{3}r)e^{-\sqrt{5r}}\\
r_{ij} &amp;= \sum_{k=1}^d\frac{(x_{ik}-z_{jk})^2}{l_k^2}
\end{aligned}\]</p><p><span>$r_{ij}$</span> are computed by <a href="#GpABC.scaled_squared_distance-Tuple{AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>scaled_squared_distance</code></a></p><p><strong>Hyperparameters</strong></p><p>The length of hyperparameters array for this kernel depends on the dimensionality of the data. Assuming each data point is a vector in a <span>$d$</span>-dimensional space, this kernel needs <span>$d+1$</span> hyperparameters, in the following order:</p><ol><li><span>$\sigma_f$</span>: the signal standard deviation</li><li><span>$l_1, \ldots, l_d$</span>: the length scales for each dimension</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tanhevg/GpABC.jl/blob/1f65a998a3ca8c20b94e4ddce05578f2ea32a3d4/src/gp/kernels/matern_kernels.jl#L54-L78">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GpABC.MaternIsoKernel" href="#GpABC.MaternIsoKernel"><code>GpABC.MaternIsoKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MaternIsoKernel &lt;: AbstractGPKernel</code></pre><p>Matérn kernel with uniform length scale across all dimensions, <span>$l$</span>. Parameter <span>$\nu$</span> (nu) is passed in constructor. Currently, only values of <span>$\nu=1$</span>, <span>$\nu=3$</span> and <span>$\nu=5$</span> are supported.</p><p class="math-container">\[\begin{aligned}
K_{\nu=1}(r) &amp;= \sigma_f^2e^{-\sqrt{r}}\\
K_{\nu=3}(r) &amp;= \sigma_f^2(1 + \sqrt{3r})e^{-\sqrt{3r}}\\
K_{\nu=5}(r) &amp;= \sigma_f^2(1 + \sqrt{3r} + \frac{5}{3}r)e^{-\sqrt{5r}}\\
r_{ij} &amp;= \sum_{k=1}^d\frac{(x_{ik}-z_{jk})^2}{l^2}
\end{aligned}\]</p><p><span>$r_{ij}$</span> are computed by <a href="#GpABC.scaled_squared_distance-Tuple{AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>scaled_squared_distance</code></a></p><p><strong>Hyperparameters</strong></p><p>Hyperparameters vector for this kernel must contain two elements, in the following order:</p><ol><li><span>$\sigma_f$</span>: the signal standard deviation</li><li><span>$l$</span>: the length scale</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tanhevg/GpABC.jl/blob/1f65a998a3ca8c20b94e4ddce05578f2ea32a3d4/src/gp/kernels/matern_kernels.jl#L8-L30">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GpABC.SquaredExponentialArdKernel" href="#GpABC.SquaredExponentialArdKernel"><code>GpABC.SquaredExponentialArdKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SquaredExponentialArdKernel &lt;: AbstractGPKernel</code></pre><p>Squared exponential kernel with distinct length scale for each dimension, <span>$l_k$</span>.</p><p class="math-container">\[\begin{aligned}
K(r) &amp; = \sigma_f^2 e^{-r/2} \\
r_{ij} &amp; = \sum_{k=1}^d\frac{(x_{ik}-z_{jk})^2}{l_k^2}
\end{aligned}\]</p><p><span>$r_{ij}$</span> are computed by <a href="#GpABC.scaled_squared_distance-Tuple{AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>scaled_squared_distance</code></a></p><p><strong>Hyperparameters</strong></p><p>The length of hyperparameters array for this kernel depends on the dimensionality of the data. Assuming each data point is a vector in a <span>$d$</span>-dimensional space, this kernel needs <span>$d+1$</span> hyperparameters, in the following order:</p><ol><li><span>$\sigma_f$</span>: the signal standard deviation</li><li><span>$l_1, \ldots, l_d$</span>: the length scales for each dimension</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tanhevg/GpABC.jl/blob/1f65a998a3ca8c20b94e4ddce05578f2ea32a3d4/src/gp/kernels/rbf_kernels.jl#L33-L52">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GpABC.SquaredExponentialIsoKernel" href="#GpABC.SquaredExponentialIsoKernel"><code>GpABC.SquaredExponentialIsoKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SquaredExponentialIsoKernel &lt;: AbstractGPKernel</code></pre><p>Squared exponential kernel with uniform length scale across all dimensions, <span>$l$</span>.</p><p class="math-container">\[\begin{aligned}
K(r) &amp; = \sigma_f^2 e^{-r/2} \\
r_{ij} &amp; = \sum_{k=1}^d\frac{(x_{ik}-z_{jk})^2}{l^2}
\end{aligned}\]</p><p><span>$r_{ij}$</span> are computed by <a href="#GpABC.scaled_squared_distance-Tuple{AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>scaled_squared_distance</code></a></p><p><strong>Hyperparameters</strong></p><p>Hyperparameters vector for this kernel must contain two elements, in the following order:</p><ol><li><span>$\sigma_f$</span>: the signal standard deviation</li><li><span>$l$</span>: the length scale</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tanhevg/GpABC.jl/blob/1f65a998a3ca8c20b94e4ddce05578f2ea32a3d4/src/gp/kernels/rbf_kernels.jl#L7-L24">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GpABC.ExponentialArdKernel-Tuple{}" href="#GpABC.ExponentialArdKernel-Tuple{}"><code>GpABC.ExponentialArdKernel</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ExponentialArdKernel</code></pre><p>Alias for <a href="#GpABC.MaternArdKernel"><code>MaternArdKernel</code></a>(1)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tanhevg/GpABC.jl/blob/1f65a998a3ca8c20b94e4ddce05578f2ea32a3d4/src/gp/kernels/matern_kernels.jl#L84-L88">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GpABC.ExponentialIsoKernel-Tuple{}" href="#GpABC.ExponentialIsoKernel-Tuple{}"><code>GpABC.ExponentialIsoKernel</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ExponentialIsoKernel</code></pre><p>Alias for <a href="#GpABC.MaternIsoKernel"><code>MaternIsoKernel</code></a>(1)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tanhevg/GpABC.jl/blob/1f65a998a3ca8c20b94e4ddce05578f2ea32a3d4/src/gp/kernels/matern_kernels.jl#L47-L51">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GpABC.scaled_squared_distance-Tuple{AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}" href="#GpABC.scaled_squared_distance-Tuple{AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>GpABC.scaled_squared_distance</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">scaled_squared_distance(log_ell::AbstractArray{Float64, 1},
    x::AbstractArray{Float64, 2}, z::AbstractArray{Float64, 2})</code></pre><p>Compute the scaled squared distance between <code>x</code> and <code>z</code>:</p><p class="math-container">\[r_{ij} = \sum_{k=1}^d\frac{(x_{ik}-z_{jk})^2}{l_k^2}\]</p><p>The gradient of this function with respect to length scale hyperparameter(s) is returned by <a href="#GpABC.scaled_squared_distance_grad-Tuple{AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>scaled_squared_distance_grad</code></a>.</p><p><strong>Arguments</strong></p><ul><li><code>x, z</code>: Input data, reshaped into 2-d arrays. <code>x</code> must have dimensions <span>$n \times d$</span>; <code>z</code> must have dimensions <span>$m \times d$</span>.</li><li><code>log_ell</code>: logarithm of length scale(s). Can either be an array of size one (isotropic), or an array of size <code>d</code> (ARD)</li></ul><p><strong>Return</strong></p><p>An <span>$n \times m$</span> matrix of scaled squared distances</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tanhevg/GpABC.jl/blob/1f65a998a3ca8c20b94e4ddce05578f2ea32a3d4/src/gp/kernels/scaled_squared_distance.jl#L1-L20">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GpABC.scaled_squared_distance_grad-Tuple{AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}" href="#GpABC.scaled_squared_distance_grad-Tuple{AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>GpABC.scaled_squared_distance_grad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">scaled_squared_distance_grad(log_ell::AbstractArray{Float64, 1},
    x::AbstractArray{Float64, 2}, z::AbstractArray{Float64, 2}, R::AbstractArray{Float64, 2})</code></pre><p>Return the gradient of the <a href="#GpABC.scaled_squared_distance-Tuple{AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>scaled_squared_distance</code></a> function with respect to logarithms of length scales, based on the provided direction matrix.</p><p><strong>Arguments</strong></p><ul><li><code>x, z</code>: Input data, reshaped into 2-d arrays. <code>x</code> must have dimensions <span>$n \times d$</span>; <code>z</code> must have dimensions <span>$m \times d$</span>.</li><li><code>log_ell</code>: logarithm of length scale(s). Can either be an array of size one (isotropic), or an array of size <code>d</code> (ARD)</li><li><code>R</code> the direction matrix, <span>$n \times m$</span>. This can be used to compute the gradient of a function that depends on <a href="#GpABC.scaled_squared_distance-Tuple{AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}"><code>scaled_squared_distance</code></a> via the chain rule.</li></ul><p><strong>Return</strong></p><p>A vector of size <code>length(log_ell)</code>, whose <span>$k$</span>&#39;th element is equal to</p><p class="math-container">\[\text{tr}(R \frac{\partial K}{\partial l_k})\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tanhevg/GpABC.jl/blob/1f65a998a3ca8c20b94e4ddce05578f2ea32a3d4/src/gp/kernels/scaled_squared_distance.jl#L45-L65">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../ref-gp/">« Gaussian Processes</a><a class="docs-footer-nextpage" href="../faq/">FAQ »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Tuesday 31 January 2023 16:32">Tuesday 31 January 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
